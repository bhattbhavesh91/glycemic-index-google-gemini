{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Glycemic Index Recommendation using Google's Gemini Pro Vision | Python | Google AI Studio\n",
        "\n",
        "[**Link to my YouTube Channel**](https://www.youtube.com/BhaveshBhatt8791?sub_confirmation=1)\n",
        "\n",
        "Click on the link below to open a Colab version of the notebook. You will be able to create your own version."
      ],
      "metadata": {
        "id": "g1va5YGucMBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhattbhavesh91/glycemic-index-google-gemini/blob/main/glycemic-index-notebook.ipynb\" target=\"_blank\"><img height=\"40\" alt=\"Run your own notebook in Colab\" src = \"https://colab.research.google.com/assets/colab-badge.svg\"></a>"
      ],
      "metadata": {
        "id": "ZpFI4r4VcRsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "J62Ed6jNukYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-generativeai==0.3.1\n",
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "CmIAwGt-ko5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add0f0a3-9d00-4261-a12e-6be61617d66d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.1/305.1 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "YKHL6-D5uoBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from pathlib import Path\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "Ad7x23Khq65P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version"
      ],
      "metadata": {
        "id": "i6Nu9YMGupE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.__version__"
      ],
      "metadata": {
        "id": "HFVBV3vAqUQS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7dc7ff6c-f04e-464a-ce1b-b958b034679d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.3.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Secret Key"
      ],
      "metadata": {
        "id": "Hk9ttrymuqs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "genai.configure(api_key = userdata.get('GEMINI_KEY'))"
      ],
      "metadata": {
        "id": "Hiho5AC_l-rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurations"
      ],
      "metadata": {
        "id": "SW4mMVLhusW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.4,\n",
        "  \"top_p\": 1,\n",
        "  \"top_k\": 32,\n",
        "  \"max_output_tokens\": 4096,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  }\n",
        "]"
      ],
      "metadata": {
        "id": "ZJr0xFY0Yosd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Instance"
      ],
      "metadata": {
        "id": "CHgH7IzeuuIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name = \"gemini-pro-vision\",\n",
        "                              generation_config = generation_config,\n",
        "                              safety_settings = safety_settings)"
      ],
      "metadata": {
        "id": "TcTI_tbDmQc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Input Function"
      ],
      "metadata": {
        "id": "1S0fg5MUuvyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def input_image_setup(file_loc):\n",
        "    if not (img := Path(file_loc)).exists():\n",
        "        raise FileNotFoundError(f\"Could not find image: {img}\")\n",
        "\n",
        "    image_parts = [\n",
        "        {\n",
        "            \"mime_type\": \"image/jpeg\",\n",
        "            \"data\": Path(file_loc).read_bytes()\n",
        "            }\n",
        "        ]\n",
        "    return image_parts"
      ],
      "metadata": {
        "id": "0E2-Ibrlmsd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response Function"
      ],
      "metadata": {
        "id": "UihTlegfux1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_gemini_response(input_prompt, image_loc):\n",
        "\n",
        "    image_prompt = input_image_setup(image_loc)\n",
        "    prompt_parts = [input_prompt, image_prompt[0]]\n",
        "    response = model.generate_content(prompt_parts)\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "BNhHA3DosY9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt"
      ],
      "metadata": {
        "id": "-mU3ZfiZuzsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_prompt = \"\"\"\n",
        "               As an expert specializing in assessing the suitability of fruits and foods for individuals with diabetes, your task involves analyzing input images featuring various food items. Your first objective is to identify the type of fruit or food present in the image. Subsequently, you must determine the glycemic index of the identified item. Based on this glycemic index, provide recommendations on whether individuals with diabetes can include the detected food in their diet. If the food is deemed suitable, specify the recommended quantity for consumption.\n",
        "               \"\"\""
      ],
      "metadata": {
        "id": "jU3d3Lhom7My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Interface"
      ],
      "metadata": {
        "id": "5DWQeCXkqOmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_file(files):\n",
        "    file_paths = [file.name for file in files]\n",
        "    if file_paths:\n",
        "        response = generate_gemini_response(input_prompt, file_paths[0])\n",
        "    return  file_paths[0], response\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    file_output = gr.Textbox()\n",
        "    image_output = gr.Image()\n",
        "    combined_output = [image_output, file_output]\n",
        "    upload_button = gr.UploadButton(\"Click to Upload an Image of the Food that you want to eat\",\n",
        "                                    file_types=[\"image\"],\n",
        "                                    file_count=\"multiple\")\n",
        "    upload_button.upload(upload_file, upload_button, combined_output)\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "xQHjtjaY1c-d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "25caa882-cfc8-4ace-c9fb-7c5b5979fb33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://6f244580e7d5bf8caf.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6f244580e7d5bf8caf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://6f244580e7d5bf8caf.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8pcZiMsx1tUM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}